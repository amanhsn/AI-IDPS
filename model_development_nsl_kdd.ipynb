{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da2e873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ§  Model Development & Evaluation\n",
    "\n",
    "# ðŸ“¦ Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "\n",
    "# Load data\n",
    "DATA_DIR = 'data/processed/'\n",
    "\n",
    "X_train = np.load(DATA_DIR + 'X_train.npy')\n",
    "y_train = np.load(DATA_DIR + 'y_train.npy')\n",
    "X_test = np.load(DATA_DIR + 'X_test.npy')\n",
    "y_test = np.load(DATA_DIR + 'y_test.npy')\n",
    "\n",
    "X_train_pca = np.load(DATA_DIR + 'X_train_pca.npy')\n",
    "X_test_pca = np.load(DATA_DIR + 'X_test_pca.npy')\n",
    "\n",
    "# ðŸ“Š Evaluation Function\n",
    "def evaluate_model(model, X, y_true):\n",
    "    y_pred = model.predict(X)\n",
    "    y_prob = model.predict_proba(X)[:, 1] if hasattr(model, 'predict_proba') else y_pred\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"ROC-AUC:\", roc_auc_score(y_true, y_prob))\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "    plt.plot(fpr, tpr, label='ROC Curve')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# âœ… Train and Evaluate on Full Feature Set\n",
    "print(\"=== Logistic Regression (Full) ===\")\n",
    "lr_full = LogisticRegression(max_iter=1000)\n",
    "lr_full.fit(X_train, y_train)\n",
    "evaluate_model(lr_full, X_test, y_test)\n",
    "\n",
    "print(\"=== Random Forest (Full) ===\")\n",
    "rf_full = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_full.fit(X_train, y_train)\n",
    "evaluate_model(rf_full, X_test, y_test)\n",
    "\n",
    "print(\"=== XGBoost (Full) ===\")\n",
    "xgb_full = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_full.fit(X_train, y_train)\n",
    "evaluate_model(xgb_full, X_test, y_test)\n",
    "\n",
    "# âœ… Train and Evaluate on PCA-Reduced Feature Set\n",
    "print(\"=== Logistic Regression (PCA) ===\")\n",
    "lr_pca = LogisticRegression(max_iter=1000)\n",
    "lr_pca.fit(X_train_pca, y_train)\n",
    "evaluate_model(lr_pca, X_test_pca, y_test)\n",
    "\n",
    "print(\"=== Random Forest (PCA) ===\")\n",
    "rf_pca = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_pca.fit(X_train_pca, y_train)\n",
    "evaluate_model(rf_pca, X_test_pca, y_test)\n",
    "\n",
    "print(\"=== XGBoost (PCA) ===\")\n",
    "xgb_pca = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_pca.fit(X_train_pca, y_train)\n",
    "evaluate_model(xgb_pca, X_test_pca, y_test)\n",
    "\n",
    "# ðŸ’¾ Save best models\n",
    "joblib.dump(xgb_full, DATA_DIR + 'xgb_full_model.joblib')\n",
    "joblib.dump(xgb_pca, DATA_DIR + 'xgb_pca_model.joblib')\n",
    "print(\"âœ… Models saved!\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
